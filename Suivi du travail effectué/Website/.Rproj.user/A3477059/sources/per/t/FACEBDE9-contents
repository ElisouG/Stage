---
title: "Troubleshooting"
output:
   html_document: 
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 5
    toc_float: yes
---

* * * * * 

# Using snpEff

snpEff est utilisé pour déterminer les effets des SNPs déposés sur le puce Affymetrix qui sera utilisée dans le cadre de la recherche des SNPs liés à la réponse au stress de *Dicentrarchus labrax*.
Comme cette espèce est très peu étudiée (pas disponible dans la plupart des base de données existantes), il faut construire une base de données à partir d'un fichier d'annotation du génome de *Dicentrarchus labrax*. Ensuite, il est possible d'analyser les effects des SNPs (au format VCF). Pour cela il faut lancer l'analyse. Lors du lacement de cette analyse différents problèmes sont apparus (All definitions are from [SnpEff manual](http://snpeff.sourceforge.net/SnpEff_manual.html) website) : 

* WARNING_TRANSCRIPT_INCOMPLETE	: A protein coding transcript having a non-multiple of 3 length. It indicates that the reference genome has missing information about this particular transcript.

* WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS	: A protein coding transcript has two or more STOP codons in the middle of the coding sequence (CDS). This should not happen and it usually means the reference genome may have an error in this transcript.

* WARNING_TRANSCRIPT_NO_START_CODON	: A protein coding transcript does not have a proper START codon. It is rare that a real transcript does not have a START codon, so this probably indicates an error or missing information in the reference genome.

* WARNING_TRANSCRIPT_NO_STOP_CODON	

Pour résoudre ces "warnings" provenant finalement d'un problème d'annotation du génome de *Dicentrarchus Labrax*, je crée un script en langage [Python](https://www.python.org/) pour récupérer ces erreurs ("warnings") pour les corriger au sein du fichier d'annotation.

# Using GATK and wdl

Pour le moment GATK est utilisé dans le but de trouver des SNPs à partir de fichiers Bam issus du Projet CRECHE de 2016. 
C'est fichiers BAM ont été obtenus par séquençage. 

Le séquençage a été réalisé en paired-end 2x150bp. Les données ont été nettoyées avec trimmomatic et alignées sur le génome avec [TopHat2](https://ccb.jhu.edu/software/tophat/index.shtml). La suite a été faite avec [cufflinks](http://cole-trapnell-lab.github.io/cufflinks/) puis [cuffmerge](http://software.broadinstitute.org/cancer/software/genepattern/modules/docs/Cuffmerge/3). Tout cela a été effectué en suivant l'ordre alphanumérique des chromosomes, aussi bien dans le fichier d'annotation de référence utilisé : Combined-annotation_Labrax-2014_Ordered.gtf que dans le fichier fasta du génome. Cela donne donc : LG10 à LG19 puis LG1A, LG1B, LG2, LG20, LG22-25, LG24, puis LG3 à LG9, LGx, MT et enfin UN.

Pour commencer je me suis référée au [Bonnes Pratiques pour utiliser GATK lorsque l'on fait du RNA-seq](https://software.broadinstitute.org/gatk/documentation/article?id=4067). 
J'ai donc ensuite écrit plusieurs scripts en m'aidant des différents tutoriels disponibles [ici](https://software.broadinstitute.org/wdl/documentation/topic?name=wdl-tutorials).

Le premier me permet de préprocesser les données afin d'obtenir des données prêtes à être processées. Ce script s'appelle : "Data_PreProcessing.wdl". Lorsque je lance ce script sur le cluster différentes erreurs sont apparues. Le première erreur est un défaut d'ordre entre le fichier fasta et les fichiers bam. Pour résoudre ce problème, j'ai donc écrit un nouveau script afin de réordrer les reads des fichiers bam en fonction du fichier fasta à ma disposition.
D'autre part, dans les Bonnes Pratiques pour utiliser GATK lorsque l'on fait du RNA-seq, il recommande d'utiliser l'outil d'alignement nommé *BWA* avec *l'algorithme mem* et *l'option -M* pour être compatible avec la suite d'outil de GATK et notamment l'outil Picard et l'option *MarkDuplicates*. L'option -M permet de faire l'alignement des splices-jonctions en second pour que les données soient compatibles avec MarkDuplicates. Pour plus de détails voir [ici](http://bio-bwa.sourceforge.net/bwa.shtml). Or TopHat2 est un aligneur de short-reads qui réalise aussi une analyse de splice-jonctions. Je me suis alors demandée si GATK et TopHat2 étaient compatibles. J'ai donc ajouté l'étape de réordrage au début de mon script "Data_PreProcessing.wdl" [Voir paragraphe suivant pour comprendre en détail].

Hors en vérifiant c'est bien le cas. TopHat2 donne les niveaux de qualité de 255 qui sont considérés par GATK comme des niveau de qualité null et les reads ayant cette qualité sont ignorés. [Cf](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_engine_filters_ReassignOneMappingQualityFilter.php). Donc j'ai lancé un changement de cette qualité mais pour ce faire il faut utiliser GATK3.8.0 et non GATK4.0.3.0. Sauf qu'ensuite un nouveau problème est apparu : L'ordre des chromosomes n'est pas le même dans le bam et dans le fasta. Donc j'ai dû ajouté une nouvelle étape qui va réordrer les reads en fonction des contigs du fichier fasta. [Cf](https://software.broadinstitute.org/gatk/documentation/article.php?id=1328). J'ai donc créé un second script nommé "ReassignOneMappingQualityFilter.wdl" qui réalise ces deux étapes. Comme ça ne fonctionnait toujours pas après plusieurs lancement et changement j'ai décidé de changer mon fusil d'épaule et de chercher si 255 était la bonne valuer or je viens de trouver [ceci](https://gatkforums.broadinstitute.org/gatk/discussion/7227/mapq-60-is-compulsory-for-the-whole-of-gatk-pipeline) qui dit que TopHat2 donne une valeur de 50 et que cette valeur de 50 est prise en compte donc pas besoin de faire ce réassignement de score. Ce script est dorénavant inutile.

Le troisième script nommé "Data_Processing.wdl" me permet de processer mes données pour qu'elles soient ensuite analysables. Comme le VQSR n'est pas disponible pour les données de RNA-seq (Cf : Les Bonnes Pratiques pour utiliser GATK lorsque l'on fait du RNA-seq). Il me faut réaliser un hardfiltering. Mais comment choisir ces filtres ? Pour cela, je me suis référée à plusieurs sites. Le [premier](https://software.broadinstitute.org/gatk/documentation/article.php?id=1255) pour comprendre le fonctionnement des JEXL (Java EXpression Language) pour l'écriture des filtres, le [second](https://software.broadinstitute.org/gatk/documentation/article.php?id=3225) qui explique pourquoi il vaut mieux faire un HardFiltering dans mon cas et le [dernier](https://software.broadinstitute.org/gatk/documentation/article.php?id=6925) pour comprendre et adapter les recommendations de HardFiltering.




